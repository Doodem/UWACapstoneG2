{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "901117c3-16b8-48c3-99b3-c1914ea90db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02573a8f-6c26-4a1f-b9d5-e1f7e46b0b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx.api import Document\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02dbc4ef-432d-40aa-bdb0-bd47fec70aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content(headings,document):    \n",
    "    '''\n",
    "    extract text after heading, currently just testing function on grabbing \n",
    "    text after introduction heading.\n",
    "    \n",
    "    headings: list of headings you want to extract text from \n",
    "    document: document to parse\n",
    "    '''    \n",
    "    content = []\n",
    "    iters = 0\n",
    "    while headings:          \n",
    "        \n",
    "        if document.paragraphs[iters].style.name.startswith(\"Heading\") and document.paragraphs[iters].text in headings:\n",
    "            heading_name = document.paragraphs[iters].text\n",
    "            content.append(heading_name)\n",
    "            while document.paragraphs[iters+1].style.name.startswith(\"Body\"):                \n",
    "                content.append(document.paragraphs[iters+1].text)\n",
    "                iters+=1            \n",
    "            headings.remove(heading_name)\n",
    "            continue\n",
    "        iters+=1\n",
    "    \n",
    "    return content  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7b1f0d-a563-47cc-93b5-145c26385474",
   "metadata": {},
   "source": [
    "<h3>Word TF-IDF<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41124ec3-a6c9-4fde-a238-16f94de2aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data \n",
    "document = Document(r\"C:\\Users\\Andre Italiano\\Desktop\\masters folder\\semester 2 2023\\capstone project files\\test.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fb96a32-832d-4c28-8337-ae4dead946af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Headings = []\n",
    "for item in document.paragraphs:\n",
    "    if item.style.name.startswith(\"Heading\"):\n",
    "        Headings.append(item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b58322d0-16ba-4848-85f3-254fe7f3261c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "                    \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                    \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                    \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \n",
    "                    \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \n",
    "                    \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n",
    "                    \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \n",
    "                    \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "                    \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
    "                    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \n",
    "                    \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "                    \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
    "                    \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \n",
    "                    \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \n",
    "                    \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \n",
    "                    \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \n",
    "                    \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \n",
    "                    \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \n",
    "                    \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \n",
    "                    \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
    "                    \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a47b63d-676f-42c8-9075-230e52267ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Andre\n",
      "[nltk_data]     Italiano\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "def pre_process(text):\n",
    "    processed_text = []\n",
    "    for item in text:\n",
    "        item = item.lower()\n",
    "        for word, new_word in contraction_dict.items():\n",
    "            item = item.replace(word, new_word)\n",
    "        item = re.sub(r'[^\\w\\s]',' ',item)\n",
    "        output = word_tokenize(item)\n",
    "        processed_text.extend(output)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16270e-7d59-4627-b49c-72f4a8210ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9883386f-4a01-49b3-bba4-2bd8c3168e39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = pre_process(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c73fd986-c723-49eb-9db0-4d76c105d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(docs):\n",
    "    tfidf_dict = dict()\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    tfidf_matrix = vectorizer.fit_transform([docs])\n",
    "    tfidf_array = tfidf_matrix.toarray()\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    for x,y in zip(terms,tfidf_array[0]):\n",
    "        tfidf_dict[x] = y\n",
    "    return tfidf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c0b623e-4c76-4675-8f71-e6e29811d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = \"\"\n",
    "for item in x:\n",
    "    l = l + \" \" + item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2dfd8fc0-68f1-4c2e-92f7-efeb36c418d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_tfidf(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "12bdebf0-a6b0-4303-97f1-96c491b7ec7f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06706527510148438 ability\n",
      "0.09687206403547745 acceptance\n",
      "0.05961357786798612 access\n",
      "0.07451697233498265 accounting\n",
      "0.08196866956848091 accounts\n",
      "0.05961357786798612 act\n",
      "0.05216188063448785 ap\n",
      "0.06706527510148438 approval\n",
      "0.06706527510148438 business\n",
      "0.06706527510148438 card\n",
      "0.05961357786798612 cash\n",
      "0.2757127976394358 ccwa\n",
      "0.05216188063448785 centre\n",
      "0.1043237612689757 compliance\n",
      "0.08196866956848091 conditions\n",
      "0.1266788529694705 contract\n",
      "0.11922715573597224 contractor\n",
      "0.05216188063448785 cost\n",
      "0.05216188063448785 credit\n",
      "0.32787467827392364 customer\n",
      "0.17884073360395836 data\n",
      "0.05216188063448785 delivery\n",
      "0.05961357786798612 details\n",
      "0.06706527510148438 electronic\n",
      "0.05216188063448785 ensure\n",
      "0.06706527510148438 file\n",
      "0.05216188063448785 files\n",
      "0.1043237612689757 financial\n",
      "0.09687206403547745 following\n",
      "0.05961357786798612 functionality\n",
      "0.08942036680197918 general\n",
      "0.08196866956848091 including\n",
      "0.05961357786798612 information\n",
      "0.07451697233498265 integration\n",
      "0.07451697233498265 ledger\n",
      "0.05216188063448785 maintain\n",
      "0.07451697233498265 manage\n",
      "0.14158224743646702 management\n",
      "0.05961357786798612 master\n",
      "0.13413055020296877 offer\n",
      "0.05961357786798612 offers\n",
      "0.09687206403547745 process\n",
      "0.05961357786798612 procurement\n",
      "0.05216188063448785 project\n",
      "0.09687206403547745 provide\n",
      "0.05216188063448785 provided\n",
      "0.05961357786798612 purchase\n",
      "0.06706527510148438 report\n",
      "0.06706527510148438 reporting\n",
      "0.07451697233498265 reports\n",
      "0.11177545850247397 request\n",
      "0.05216188063448785 require\n",
      "0.08196866956848091 required\n",
      "0.23845431147194449 requirements\n",
      "0.05961357786798612 requires\n",
      "0.1937441280709549 respondent\n",
      "0.07451697233498265 schedule\n",
      "0.05216188063448785 section\n",
      "0.05961357786798612 services\n",
      "0.24590600870544274 solution\n",
      "0.05216188063448785 state\n",
      "0.09687206403547745 support\n",
      "0.05216188063448785 tax\n",
      "0.05216188063448785 tenders\n",
      "0.05216188063448785 test\n",
      "0.1490339446699653 testing\n",
      "0.05961357786798612 training\n",
      "0.06706527510148438 transactions\n",
      "0.08942036680197918 user\n",
      "0.14158224743646702 users\n",
      "0.05216188063448785 value\n",
      "0.08942036680197918 wa\n"
     ]
    }
   ],
   "source": [
    "for item in list(output.keys()):\n",
    "    if output[item] > 0.05:\n",
    "        print(output[item],item)\n",
    "        \n",
    "# fairly uninformative so far, may need to remove parts of document that are boilerplate, will continue on 15/08/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6079d5-d03a-40bc-be2b-5d15b260a01f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
