{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6740039-df21-4241-8665-629ece8a809f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_cpp import Llama, llama_cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a972b07-b3ca-44e6-944c-d427fb8505b6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from ../../../../Models/llama-2-7b.Q4_K_M.gguf (version GGUF V2 (latest))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q4_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:           blk.15.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.15.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:             blk.15.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:             blk.15.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:        blk.15.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:             blk.15.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:             blk.15.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:           blk.16.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.16.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:             blk.16.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:             blk.16.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:        blk.16.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:             blk.16.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:             blk.16.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:           blk.17.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.17.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:             blk.17.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:             blk.17.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:        blk.17.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:             blk.17.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:             blk.17.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:           blk.18.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.18.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:             blk.18.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.18.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:        blk.18.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:             blk.18.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:             blk.18.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:           blk.19.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.19.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:             blk.19.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.19.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:        blk.19.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:             blk.19.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:             blk.19.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:            blk.2.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:            blk.2.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:              blk.2.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.2.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:         blk.2.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.2.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:              blk.2.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:           blk.20.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.20.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.20.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.20.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:        blk.20.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:             blk.20.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:             blk.20.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:           blk.21.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.21.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:             blk.21.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.21.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:        blk.21.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:             blk.21.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:             blk.21.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:           blk.22.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:           blk.22.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.22.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.22.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:        blk.22.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:             blk.22.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.22.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.23.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.23.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.23.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.23.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.23.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.23.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.23.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:            blk.3.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:            blk.3.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:              blk.3.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:              blk.3.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:         blk.3.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:              blk.3.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:              blk.3.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:            blk.4.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:            blk.4.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:              blk.4.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:              blk.4.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:         blk.4.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:              blk.4.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:              blk.4.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:            blk.5.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:            blk.5.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:              blk.5.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:              blk.5.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:         blk.5.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:              blk.5.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:              blk.5.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:            blk.6.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:            blk.6.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:              blk.6.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:              blk.6.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:         blk.6.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:              blk.6.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:              blk.6.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:            blk.7.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:            blk.7.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:              blk.7.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:              blk.7.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:         blk.7.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:              blk.7.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:              blk.7.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:            blk.8.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:            blk.8.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:              blk.8.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:              blk.8.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:         blk.8.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:              blk.8.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:              blk.8.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:            blk.9.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:            blk.9.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:              blk.9.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:              blk.9.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:         blk.9.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:              blk.9.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:              blk.9.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:           blk.24.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:             blk.24.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:             blk.24.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:        blk.24.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.24.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:           blk.25.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:             blk.25.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:             blk.25.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:        blk.25.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.25.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_down.weight q4_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:           blk.26.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:             blk.26.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:             blk.26.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:        blk.26.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.26.attn_v.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:           blk.27.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:             blk.27.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:             blk.27.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:        blk.27.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.27.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:           blk.28.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:             blk.28.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:             blk.28.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:        blk.28.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.28.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:           blk.29.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:             blk.29.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:             blk.29.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:        blk.29.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.29.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:           blk.30.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:           blk.30.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:             blk.30.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:        blk.30.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:             blk.30.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.30.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q4_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                          general.file_type u32     \n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  18:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_print_meta: format           = GGUF V2 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name   = LLaMA v2\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.09 MB\n",
      "llm_load_tensors: mem required  = 3891.34 MB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  =  256.00 MB\n",
      "llama_new_context_with_model: compute buffer total size = 76.38 MB\n"
     ]
    }
   ],
   "source": [
    "llm = Llama(model_path=\"../../../../Models/llama-2-7b.Q4_K_M.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff487c3-d2c8-4cbf-9e19-391230231f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "llama_save_path = \"../../../../data/llama_embeddings/\"\n",
    "some_tender = list(numpy.load(os.path.join(llama_save_path, \"DOJ202226168H.npy\"))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bf3ed63-7952-4736-a221-bcfb8b02051e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_cpp.llama_eval_embd(llm.ctx, (llama_cpp.c_float * len(some_tender))(*some_tender), 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "399f301d-7a36-40bd-b840-70466d7122af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7722622752189636,\n",
       " 0.9696961045265198,\n",
       " 0.8352591395378113,\n",
       " -1.295852541923523,\n",
       " -0.6024028062820435,\n",
       " -0.2366628348827362,\n",
       " 0.7635444402694702,\n",
       " 2.2271242141723633,\n",
       " 1.4522809982299805,\n",
       " 1.4172836542129517,\n",
       " 0.7894003391265869,\n",
       " 0.9765252470970154,\n",
       " 2.4179532527923584,\n",
       " -0.04545697569847107,\n",
       " -1.7884960174560547,\n",
       " -1.8576946258544922,\n",
       " 0.6464561223983765,\n",
       " -1.084194540977478,\n",
       " -1.1849372386932373,\n",
       " -2.6320383548736572,\n",
       " 0.6666560173034668,\n",
       " -1.5347877740859985,\n",
       " 1.0071241855621338,\n",
       " -1.5751404762268066,\n",
       " 1.2413971424102783,\n",
       " 0.8777667284011841,\n",
       " -1.827904462814331,\n",
       " -0.8818585872650146,\n",
       " -2.277683734893799,\n",
       " 0.34734272956848145,\n",
       " 0.08664681017398834,\n",
       " -2.0775134563446045,\n",
       " -1.2345672845840454,\n",
       " 1.8692833185195923,\n",
       " 2.7778408527374268,\n",
       " -2.3808858394622803,\n",
       " -0.320537805557251,\n",
       " -0.7534486055374146,\n",
       " -0.7211663126945496,\n",
       " 0.6398970484733582,\n",
       " -0.16032147407531738,\n",
       " -5.768032073974609,\n",
       " -1.9169138669967651,\n",
       " -1.9932161569595337,\n",
       " 1.775328278541565,\n",
       " 2.284116744995117,\n",
       " 1.5056827068328857,\n",
       " 0.09132730215787888,\n",
       " 1.8240082263946533,\n",
       " -2.851254463195801,\n",
       " 0.06574361026287079,\n",
       " 0.12458503991365433,\n",
       " 0.39131662249565125,\n",
       " -1.9242689609527588,\n",
       " 0.785805881023407,\n",
       " -1.7933889627456665,\n",
       " 1.4900773763656616,\n",
       " 3.6232964992523193,\n",
       " 0.3024098575115204,\n",
       " -1.8617448806762695,\n",
       " -2.976024627685547,\n",
       " -1.655734896659851,\n",
       " 1.2237859964370728,\n",
       " 2.519376277923584,\n",
       " -3.2181944847106934,\n",
       " -1.5662060976028442,\n",
       " -1.1169320344924927,\n",
       " 0.046102374792099,\n",
       " -0.6470375657081604,\n",
       " -1.4394758939743042,\n",
       " -0.05605797469615936,\n",
       " 0.02768961898982525,\n",
       " -1.5244094133377075,\n",
       " 0.7728171944618225,\n",
       " -5.466643333435059,\n",
       " 0.9779419898986816,\n",
       " 4.037839412689209,\n",
       " -0.8413428068161011,\n",
       " -1.2096481323242188,\n",
       " 0.463905930519104,\n",
       " 4.699570178985596,\n",
       " -0.8029561638832092,\n",
       " 1.970590353012085,\n",
       " -4.214334011077881,\n",
       " -0.9890639781951904,\n",
       " 1.089451551437378,\n",
       " -0.28246432542800903,\n",
       " 1.5780962705612183,\n",
       " 1.9537791013717651,\n",
       " -0.274183988571167,\n",
       " -0.8659201860427856,\n",
       " -0.971511960029602,\n",
       " 0.18610267341136932,\n",
       " -0.7520866394042969,\n",
       " -1.2874122858047485,\n",
       " 1.4227030277252197,\n",
       " -1.1686387062072754,\n",
       " 0.4449807405471802,\n",
       " 0.4577469825744629,\n",
       " -2.6086909770965576,\n",
       " -2.289295196533203,\n",
       " -1.7675212621688843,\n",
       " 0.9031918048858643,\n",
       " 0.8788822293281555,\n",
       " -0.6557248830795288,\n",
       " 2.3711185455322266,\n",
       " -0.9754694104194641,\n",
       " 0.06796763092279434,\n",
       " -0.1571376770734787,\n",
       " -1.2072418928146362,\n",
       " 2.5465750694274902,\n",
       " -0.4739919900894165,\n",
       " -2.6189067363739014,\n",
       " 0.5260970592498779,\n",
       " 0.5801722407341003,\n",
       " -0.012033813633024693,\n",
       " -1.4693020582199097,\n",
       " 0.6547821164131165,\n",
       " -0.3280332386493683,\n",
       " -1.3889034986495972,\n",
       " -0.40215668082237244,\n",
       " 0.042999736964702606,\n",
       " 0.08579383790493011,\n",
       " -0.28981125354766846,\n",
       " 1.2456501722335815,\n",
       " 0.5683197379112244,\n",
       " 0.45577681064605713,\n",
       " -2.0963661670684814,\n",
       " 1.6616185903549194,\n",
       " -1.6534829139709473,\n",
       " 0.4844657778739929,\n",
       " -0.43577826023101807,\n",
       " 0.8998684287071228,\n",
       " 1.8170521259307861,\n",
       " 0.05378194525837898,\n",
       " 2.77970814704895,\n",
       " 0.35779091715812683,\n",
       " -0.4517524838447571,\n",
       " -2.10109806060791,\n",
       " 0.02368072234094143,\n",
       " 1.5574568510055542,\n",
       " -0.8567004799842834,\n",
       " 1.5912076234817505,\n",
       " 0.8581557273864746,\n",
       " 0.7435868382453918,\n",
       " 1.3685009479522705,\n",
       " 0.915515661239624,\n",
       " -0.07415175437927246,\n",
       " 1.6453481912612915,\n",
       " -0.7361782193183899,\n",
       " -0.152662992477417,\n",
       " 1.0332367420196533,\n",
       " -1.5102930068969727,\n",
       " -1.2218029499053955,\n",
       " -0.11167039722204208,\n",
       " -0.9388585686683655,\n",
       " -0.4428381323814392,\n",
       " -1.3859080076217651,\n",
       " -1.3804634809494019,\n",
       " -0.36971578001976013,\n",
       " 0.24202841520309448,\n",
       " -0.7724084854125977,\n",
       " 0.21567180752754211,\n",
       " 2.3132214546203613,\n",
       " -1.5232115983963013,\n",
       " -1.063671350479126,\n",
       " 1.7492001056671143,\n",
       " -0.5584548711776733,\n",
       " 3.190173625946045,\n",
       " -0.9350301623344421,\n",
       " 0.14370852708816528,\n",
       " -0.7118386030197144,\n",
       " -0.21102572977542877,\n",
       " -1.1176400184631348,\n",
       " 1.5596822500228882,\n",
       " -1.6424108743667603,\n",
       " -1.8700228929519653,\n",
       " -2.8223865032196045,\n",
       " -0.0011108249891549349,\n",
       " -0.05508093535900116,\n",
       " -0.14486205577850342,\n",
       " -0.9237154722213745,\n",
       " -0.11460143327713013,\n",
       " -0.4959580898284912,\n",
       " -0.32501542568206787,\n",
       " -0.1685115247964859,\n",
       " 2.958858013153076,\n",
       " 2.37868595123291,\n",
       " -1.5685181617736816,\n",
       " 0.2834307551383972,\n",
       " 0.9384886026382446,\n",
       " -0.9096803069114685,\n",
       " -0.5006296634674072,\n",
       " -0.7821676731109619,\n",
       " 1.004755973815918,\n",
       " -1.315271258354187,\n",
       " -2.203806161880493,\n",
       " -0.15285082161426544,\n",
       " -1.1780874729156494,\n",
       " 0.10331045091152191,\n",
       " -0.47760069370269775,\n",
       " 0.15613128244876862,\n",
       " -1.7018020153045654,\n",
       " 1.917597770690918,\n",
       " 1.0662627220153809,\n",
       " -0.295854777097702,\n",
       " -1.1171866655349731,\n",
       " -0.504707932472229,\n",
       " 1.522362232208252,\n",
       " -0.4522288143634796,\n",
       " -2.575970411300659,\n",
       " -0.30625125765800476,\n",
       " -2.098888874053955,\n",
       " 1.4197664260864258,\n",
       " 1.3376396894454956,\n",
       " 0.24827398359775543,\n",
       " -4.2723188400268555,\n",
       " 1.027786135673523,\n",
       " 3.863405227661133,\n",
       " -0.40118885040283203,\n",
       " -2.516381025314331,\n",
       " 2.854762554168701,\n",
       " -1.6343810558319092,\n",
       " 0.2471136897802353,\n",
       " -0.8938117623329163,\n",
       " -3.179342746734619,\n",
       " 0.09674152731895447,\n",
       " -0.3261612355709076,\n",
       " -1.027666449546814,\n",
       " -0.06717810034751892,\n",
       " -0.05695587396621704,\n",
       " 1.510029673576355,\n",
       " -3.211642265319824,\n",
       " -0.3742251396179199,\n",
       " -0.773566722869873,\n",
       " -1.0915846824645996,\n",
       " 0.06588694453239441,\n",
       " 0.7355768084526062,\n",
       " 1.3663660287857056,\n",
       " 0.6945372819900513,\n",
       " -2.341109275817871,\n",
       " -2.5688235759735107,\n",
       " 0.21901008486747742,\n",
       " 0.3978370130062103,\n",
       " -1.9547359943389893,\n",
       " 0.2060343623161316,\n",
       " -0.6634461283683777,\n",
       " -3.4887804985046387,\n",
       " -0.12804657220840454,\n",
       " -0.6948564052581787,\n",
       " 0.23227956891059875,\n",
       " -0.5310866236686707,\n",
       " -2.3972601890563965,\n",
       " -3.3714747428894043,\n",
       " 2.517828941345215,\n",
       " 2.560980796813965,\n",
       " 1.4846833944320679,\n",
       " 0.12572228908538818,\n",
       " -0.21303720772266388,\n",
       " -0.365677148103714,\n",
       " 0.40546631813049316,\n",
       " 1.6346938610076904,\n",
       " -0.1712740808725357,\n",
       " 0.8720355033874512,\n",
       " -1.1464815139770508,\n",
       " -0.03341234475374222,\n",
       " 1.907443642616272,\n",
       " -0.8951146602630615,\n",
       " -0.43763935565948486,\n",
       " -1.1233192682266235,\n",
       " -0.2543279826641083,\n",
       " 1.7034556865692139,\n",
       " 2.0274195671081543,\n",
       " 0.9276186227798462,\n",
       " -0.2900944948196411,\n",
       " -1.6790729761123657,\n",
       " 0.4209948182106018,\n",
       " 2.0290985107421875,\n",
       " -0.785280168056488,\n",
       " 0.8072028756141663,\n",
       " 0.9513489007949829,\n",
       " -0.5597432851791382,\n",
       " 0.5802459716796875,\n",
       " 2.0444490909576416,\n",
       " -3.086308002471924,\n",
       " 1.0976628065109253,\n",
       " 0.3566802144050598,\n",
       " 0.46288809180259705,\n",
       " 1.558812141418457,\n",
       " 0.7815085649490356,\n",
       " -0.6274302005767822,\n",
       " -1.759525179862976,\n",
       " -0.18078021705150604,\n",
       " -2.1356723308563232,\n",
       " 0.35770946741104126,\n",
       " -0.9606408476829529,\n",
       " -0.5715324878692627,\n",
       " 2.581737756729126,\n",
       " 0.6016296148300171,\n",
       " 0.61982262134552,\n",
       " -0.49044832587242126,\n",
       " -1.8390125036239624,\n",
       " -1.238110065460205,\n",
       " -0.16854077577590942,\n",
       " -1.359491229057312,\n",
       " 1.3462152481079102,\n",
       " 1.0961062908172607,\n",
       " -1.365342378616333,\n",
       " 0.9673844575881958,\n",
       " -2.383655548095703,\n",
       " 1.4519034624099731,\n",
       " -0.7850825190544128,\n",
       " -0.04047461599111557,\n",
       " 0.778132438659668,\n",
       " -1.2470641136169434,\n",
       " 1.3349857330322266,\n",
       " 0.09554123878479004,\n",
       " -3.689451217651367,\n",
       " -0.04111494496464729,\n",
       " -2.0801029205322266,\n",
       " -0.025096427649259567,\n",
       " 0.5187390446662903,\n",
       " -0.6844272017478943,\n",
       " 0.14968694746494293,\n",
       " -1.1848117113113403,\n",
       " -1.5861934423446655,\n",
       " 0.842195451259613,\n",
       " -2.521746873855591,\n",
       " -0.8089725375175476,\n",
       " 0.0015222342917695642,\n",
       " -1.253496766090393,\n",
       " 0.9389315843582153,\n",
       " -2.2505922317504883,\n",
       " 1.3588511943817139,\n",
       " 2.4796364307403564,\n",
       " 1.3899576663970947,\n",
       " 0.627418577671051,\n",
       " -0.33988919854164124,\n",
       " 0.359424889087677,\n",
       " -0.09191634505987167,\n",
       " 1.348359227180481,\n",
       " 1.2735321521759033,\n",
       " 0.8454535007476807,\n",
       " -0.6914349794387817,\n",
       " -0.7676776647567749,\n",
       " -1.9687858819961548,\n",
       " 2.3569414615631104,\n",
       " -0.37005242705345154,\n",
       " 0.22243745625019073,\n",
       " -0.8631304502487183,\n",
       " -0.379447340965271,\n",
       " -0.7300764918327332,\n",
       " -3.140273094177246,\n",
       " 0.04225866496562958,\n",
       " -1.1675755977630615,\n",
       " -2.1450319290161133,\n",
       " 2.261291980743408,\n",
       " -0.5776485204696655,\n",
       " -1.804072380065918,\n",
       " -0.7380576133728027,\n",
       " -0.8050084710121155,\n",
       " -0.33058470487594604,\n",
       " 0.14046965539455414,\n",
       " -2.394120931625366,\n",
       " 1.4373323917388916,\n",
       " -2.673233985900879,\n",
       " 1.3429336547851562,\n",
       " 0.6667335033416748,\n",
       " 1.719052791595459,\n",
       " -0.37537673115730286,\n",
       " -2.590198278427124,\n",
       " -1.0881316661834717,\n",
       " -1.3043997287750244,\n",
       " 0.1631547212600708,\n",
       " 1.0388782024383545,\n",
       " 0.8917698860168457,\n",
       " 1.368182897567749,\n",
       " -0.502034068107605,\n",
       " 2.1021032333374023,\n",
       " -1.2396060228347778,\n",
       " -0.6786680817604065,\n",
       " 0.7249148488044739,\n",
       " 0.37701138854026794,\n",
       " 0.33804935216903687,\n",
       " 0.4628186523914337,\n",
       " 1.8719877004623413,\n",
       " -0.9895182251930237,\n",
       " -0.5442105531692505,\n",
       " 0.6073614358901978,\n",
       " 0.3918832838535309,\n",
       " 1.5359281301498413,\n",
       " 0.3498215079307556,\n",
       " -2.404259443283081,\n",
       " -2.784959077835083,\n",
       " 0.4105936288833618,\n",
       " 2.720734119415283,\n",
       " -0.8729188442230225,\n",
       " -0.06130404770374298,\n",
       " -1.6707026958465576,\n",
       " 3.620313882827759,\n",
       " -1.6196482181549072,\n",
       " -0.9384657144546509,\n",
       " 0.5692420601844788,\n",
       " -3.658597469329834,\n",
       " -2.0065298080444336,\n",
       " 0.278121680021286,\n",
       " -4.2129225730896,\n",
       " 1.9582542181015015,\n",
       " 1.366678237915039,\n",
       " -0.775714635848999,\n",
       " 0.5417550206184387,\n",
       " -2.082552194595337,\n",
       " -1.9788497686386108,\n",
       " 0.8369392156600952,\n",
       " 1.4323424100875854,\n",
       " -0.4252707064151764,\n",
       " 0.2430926263332367,\n",
       " 1.3238078355789185,\n",
       " 1.661350965499878,\n",
       " 1.068362832069397,\n",
       " 2.231781482696533,\n",
       " 0.00588711304590106,\n",
       " 0.540928065776825,\n",
       " 1.967592477798462,\n",
       " 0.509164035320282,\n",
       " 0.6556875705718994,\n",
       " -2.4978272914886475,\n",
       " -0.39711055159568787,\n",
       " 0.24870775640010834,\n",
       " -0.590438961982727,\n",
       " 0.14229610562324524,\n",
       " -1.915663242340088,\n",
       " 2.2680680751800537,\n",
       " -0.48362869024276733,\n",
       " -0.0824335590004921,\n",
       " -1.6574734449386597,\n",
       " -1.471638798713684,\n",
       " -0.9215499758720398,\n",
       " -0.5989239811897278,\n",
       " 1.3072094917297363,\n",
       " -0.18853366374969482,\n",
       " 1.3361552953720093,\n",
       " -0.8798041343688965,\n",
       " -1.0673552751541138,\n",
       " -4.462444305419922,\n",
       " -0.6509729027748108,\n",
       " -0.9573237895965576,\n",
       " 4.0185394287109375,\n",
       " -1.92596435546875,\n",
       " 2.0109329223632812,\n",
       " 0.18999120593070984,\n",
       " 0.03882095590233803,\n",
       " 0.5887863039970398,\n",
       " 0.5151705145835876,\n",
       " 1.3693853616714478,\n",
       " -1.8639804124832153,\n",
       " -1.6576080322265625,\n",
       " -0.7832550406455994,\n",
       " -1.2222011089324951,\n",
       " -0.9695107340812683,\n",
       " -0.9103491902351379,\n",
       " 0.22728784382343292,\n",
       " -1.0589650869369507,\n",
       " 0.16398334503173828,\n",
       " 1.9815928936004639,\n",
       " -1.9307072162628174,\n",
       " -3.4235804080963135,\n",
       " 0.9014891982078552,\n",
       " -1.5295088291168213,\n",
       " 1.4174914360046387,\n",
       " -1.6219985485076904,\n",
       " 0.8780158758163452,\n",
       " 1.3705477714538574,\n",
       " -0.9204089045524597,\n",
       " -1.8124357461929321,\n",
       " -0.7196446657180786,\n",
       " -0.4838224947452545,\n",
       " -0.24682509899139404,\n",
       " 0.0795922726392746,\n",
       " -1.73807954788208,\n",
       " 0.006722851190716028,\n",
       " 0.21186722815036774,\n",
       " -1.6356738805770874,\n",
       " 1.141129970550537,\n",
       " -1.3445614576339722,\n",
       " 0.24967631697654724,\n",
       " 3.7167000770568848,\n",
       " -0.9408011436462402,\n",
       " 5.622959613800049,\n",
       " 0.5798203349113464,\n",
       " 1.645103096961975,\n",
       " 0.8422282338142395,\n",
       " 1.6906794309616089,\n",
       " 0.7600381374359131,\n",
       " 0.8098708391189575,\n",
       " 0.9948703050613403,\n",
       " -1.5801544189453125,\n",
       " 1.065029263496399,\n",
       " 0.8430063128471375,\n",
       " -1.1420211791992188,\n",
       " 2.113858461380005,\n",
       " -1.503759503364563,\n",
       " 1.5706703662872314,\n",
       " 0.8964465856552124,\n",
       " -2.135401725769043,\n",
       " -1.7328435182571411,\n",
       " 0.8357089757919312,\n",
       " -0.9883735775947571,\n",
       " 2.18467116355896,\n",
       " 3.215794801712036,\n",
       " 1.086461067199707,\n",
       " -1.6003260612487793,\n",
       " 0.5079728364944458,\n",
       " -1.993485450744629,\n",
       " 6.427010536193848,\n",
       " -1.7859923839569092,\n",
       " -1.9080246686935425,\n",
       " -0.354557067155838,\n",
       " 2.8076224327087402,\n",
       " 1.905686855316162,\n",
       " 0.7187746167182922,\n",
       " -1.9606972932815552,\n",
       " 0.32447007298469543,\n",
       " -0.9384885430335999,\n",
       " -2.190995931625366,\n",
       " 4.915267467498779,\n",
       " -1.1458665132522583,\n",
       " -0.7434614300727844,\n",
       " 1.944151520729065,\n",
       " -0.4907008409500122,\n",
       " 1.0596882104873657,\n",
       " 0.19389088451862335,\n",
       " -1.8084806203842163,\n",
       " -0.05804288387298584,\n",
       " 1.0852549076080322,\n",
       " 0.007862345315515995,\n",
       " 1.4848767518997192,\n",
       " -0.33516281843185425,\n",
       " -0.575279712677002,\n",
       " 1.5476326942443848,\n",
       " 3.360564947128296,\n",
       " 1.1159390211105347,\n",
       " -0.44210609793663025,\n",
       " -1.6625710725784302,\n",
       " 1.1921666860580444,\n",
       " -0.8244556188583374,\n",
       " 0.8695297837257385,\n",
       " 2.088524341583252,\n",
       " -1.0481854677200317,\n",
       " 0.1554589420557022,\n",
       " 0.19183416664600372,\n",
       " -0.22759924829006195,\n",
       " -1.5627058744430542,\n",
       " -2.486403465270996,\n",
       " -0.2678101062774658,\n",
       " -1.2163610458374023,\n",
       " -0.4134289026260376,\n",
       " 1.8037351369857788,\n",
       " 1.7919381856918335,\n",
       " -0.7031469345092773,\n",
       " 4.324777603149414,\n",
       " -2.5542774200439453,\n",
       " -0.44474053382873535,\n",
       " -2.428213119506836,\n",
       " -0.5973961353302002,\n",
       " -1.7821656465530396,\n",
       " -0.280748575925827,\n",
       " 0.9709669947624207,\n",
       " 0.02634400874376297,\n",
       " 2.3941843509674072,\n",
       " 1.3144418001174927,\n",
       " -2.384645700454712,\n",
       " -1.1532384157180786,\n",
       " 0.9364619851112366,\n",
       " 1.889176607131958,\n",
       " -0.25275781750679016,\n",
       " 0.7518471479415894,\n",
       " -2.2108700275421143,\n",
       " -2.246408462524414,\n",
       " 3.0222086906433105,\n",
       " 1.018875241279602,\n",
       " -0.11297742277383804,\n",
       " -0.4853964149951935,\n",
       " 1.3734463453292847,\n",
       " 0.08912495523691177,\n",
       " -0.7363734245300293,\n",
       " -0.8683919906616211,\n",
       " -1.2473900318145752,\n",
       " -5.489842891693115,\n",
       " 6.742958068847656,\n",
       " 1.3466664552688599,\n",
       " -0.8266309499740601,\n",
       " -0.14662732183933258,\n",
       " 0.3261110782623291,\n",
       " 0.15340928733348846,\n",
       " 1.255070447921753,\n",
       " -2.1913394927978516,\n",
       " 1.3161393404006958,\n",
       " -0.10106245428323746,\n",
       " -1.0332833528518677,\n",
       " 0.25226178765296936,\n",
       " 4.126359462738037,\n",
       " -0.15434899926185608,\n",
       " -0.29685959219932556,\n",
       " -0.6022579669952393,\n",
       " 0.7294761538505554,\n",
       " 0.9745263457298279,\n",
       " -0.22124814987182617,\n",
       " 0.6693607568740845,\n",
       " 1.0658177137374878,\n",
       " 1.1212488412857056,\n",
       " 1.5091867446899414,\n",
       " 0.4342069625854492,\n",
       " -2.539358377456665,\n",
       " 0.9005789756774902,\n",
       " -1.110947608947754,\n",
       " -0.5952126383781433,\n",
       " 2.8812265396118164,\n",
       " -2.678361177444458,\n",
       " 2.745919704437256,\n",
       " -1.0674257278442383,\n",
       " 3.7559882912319154e-05,\n",
       " -1.923462152481079,\n",
       " -0.23863612115383148,\n",
       " 3.455890417098999,\n",
       " -1.0493168830871582,\n",
       " 1.4688199758529663,\n",
       " -1.5401017665863037,\n",
       " 0.7914618253707886,\n",
       " 0.9543003439903259,\n",
       " -1.3063162565231323,\n",
       " 0.6458741426467896,\n",
       " -2.7480461597442627,\n",
       " 1.7007900476455688,\n",
       " 1.3123254776000977,\n",
       " -1.5859661102294922,\n",
       " 1.0930207967758179,\n",
       " 0.7673829197883606,\n",
       " -1.4634454250335693,\n",
       " 1.6302013397216797,\n",
       " -0.5213013291358948,\n",
       " -1.6783332824707031,\n",
       " -2.0226247310638428,\n",
       " 3.939770221710205,\n",
       " -2.262051582336426,\n",
       " -0.10034672170877457,\n",
       " 1.4644101858139038,\n",
       " 0.5005919337272644,\n",
       " -1.177346110343933,\n",
       " 1.822995662689209,\n",
       " -2.628589630126953,\n",
       " -0.399928480386734,\n",
       " -1.2798612117767334,\n",
       " -0.6399892568588257,\n",
       " 2.696058511734009,\n",
       " 1.2938965559005737,\n",
       " -0.2320116013288498,\n",
       " -0.4694433808326721,\n",
       " -1.6509109735488892,\n",
       " 1.493528962135315,\n",
       " -1.4239310026168823,\n",
       " 0.7167052030563354,\n",
       " 2.911196708679199,\n",
       " 0.6944406032562256,\n",
       " 0.6723073124885559,\n",
       " -0.43918129801750183,\n",
       " 0.8420277237892151,\n",
       " -0.5995409488677979,\n",
       " -2.0564749240875244,\n",
       " 0.9767455458641052,\n",
       " -1.1077975034713745,\n",
       " -1.1227432489395142,\n",
       " 1.1675692796707153,\n",
       " 3.1047143936157227,\n",
       " -2.0733883380889893,\n",
       " 1.3751155138015747,\n",
       " -1.3868004083633423,\n",
       " -1.2381399869918823,\n",
       " -2.3469202518463135,\n",
       " -1.286425232887268,\n",
       " 0.5607097744941711,\n",
       " -2.4678804874420166,\n",
       " 9.612339973449707,\n",
       " -0.5755178928375244,\n",
       " 0.7835126519203186,\n",
       " -0.4640686810016632,\n",
       " -0.8415544629096985,\n",
       " 0.3530014753341675,\n",
       " 0.4127376973628998,\n",
       " 3.1050686836242676,\n",
       " -1.6539820432662964,\n",
       " -0.4970400631427765,\n",
       " 0.9075667858123779,\n",
       " 2.1498653888702393,\n",
       " 0.6231679320335388,\n",
       " 1.0236259698867798,\n",
       " 1.3726240396499634,\n",
       " -0.6546451449394226,\n",
       " -1.0486043691635132,\n",
       " 1.0484445095062256,\n",
       " -0.5025650262832642,\n",
       " -0.2737601101398468,\n",
       " -0.2020610123872757,\n",
       " -1.249395728111267,\n",
       " 0.25761720538139343,\n",
       " -0.2617989480495453,\n",
       " 0.4275982677936554,\n",
       " -1.5362874269485474,\n",
       " -0.30916887521743774,\n",
       " -1.8720848560333252,\n",
       " 1.1348751783370972,\n",
       " -0.5201430916786194,\n",
       " -4.686657428741455,\n",
       " -0.7799583673477173,\n",
       " -1.2273564338684082,\n",
       " 1.0219910144805908,\n",
       " 1.447759985923767,\n",
       " -2.6231279373168945,\n",
       " -0.6207274198532104,\n",
       " 1.042872428894043,\n",
       " 0.2165428102016449,\n",
       " 0.9005571603775024,\n",
       " 0.30865278840065,\n",
       " -0.8248161673545837,\n",
       " 0.08533640950918198,\n",
       " -3.0590310096740723,\n",
       " 0.4255657196044922,\n",
       " -1.0200504064559937,\n",
       " -0.854200005531311,\n",
       " -2.2403504848480225,\n",
       " -1.7843738794326782,\n",
       " 2.659024238586426,\n",
       " -0.035117845982313156,\n",
       " -0.6449072360992432,\n",
       " -0.8750170469284058,\n",
       " -0.3470601439476013,\n",
       " 0.18618741631507874,\n",
       " -0.804746150970459,\n",
       " -1.4423693418502808,\n",
       " 0.9667508602142334,\n",
       " -0.17739222943782806,\n",
       " 1.0769178867340088,\n",
       " -0.815436840057373,\n",
       " -0.621722936630249,\n",
       " -1.5902485847473145,\n",
       " 3.4561362266540527,\n",
       " 1.0676764249801636,\n",
       " 0.1162203773856163,\n",
       " 0.5675007700920105,\n",
       " 1.253287672996521,\n",
       " 1.1483601331710815,\n",
       " -0.9852111339569092,\n",
       " -2.0508906841278076,\n",
       " 0.06455495953559875,\n",
       " -3.073310136795044,\n",
       " 3.9882569313049316,\n",
       " -1.3773144483566284,\n",
       " -0.4982227683067322,\n",
       " 0.34962546825408936,\n",
       " -1.1778191328048706,\n",
       " 3.3551223278045654,\n",
       " 4.496789932250977,\n",
       " -1.0571295022964478,\n",
       " -0.3485572040081024,\n",
       " -1.258824110031128,\n",
       " 2.13543963432312,\n",
       " -0.7158268690109253,\n",
       " 2.3772284984588623,\n",
       " -1.1185401678085327,\n",
       " -0.12243325263261795,\n",
       " -2.115831136703491,\n",
       " 2.010894775390625,\n",
       " 0.8254506587982178,\n",
       " -1.2899943590164185,\n",
       " 2.292454719543457,\n",
       " 2.494846820831299,\n",
       " -0.5316085815429688,\n",
       " 1.1063843965530396,\n",
       " 0.7147470712661743,\n",
       " -1.5903321504592896,\n",
       " -0.9094744324684143,\n",
       " 1.3710098266601562,\n",
       " 2.3453969955444336,\n",
       " -0.33909377455711365,\n",
       " 1.3592897653579712,\n",
       " 1.713323950767517,\n",
       " -1.4674068689346313,\n",
       " 3.5449366569519043,\n",
       " -5.773214817047119,\n",
       " 0.26660627126693726,\n",
       " 6.568743705749512,\n",
       " -3.781395196914673,\n",
       " -2.575425148010254,\n",
       " -0.03380466625094414,\n",
       " -3.4048900604248047,\n",
       " 0.09012911468744278,\n",
       " 1.3189177513122559,\n",
       " -3.474086284637451,\n",
       " -0.4406178295612335,\n",
       " -0.6182687878608704,\n",
       " -0.4209853708744049,\n",
       " -0.0030919923447072506,\n",
       " 0.4201023280620575,\n",
       " 2.956169843673706,\n",
       " 1.686598777770996,\n",
       " 0.8863428235054016,\n",
       " 1.7746026515960693,\n",
       " -2.505584955215454,\n",
       " 0.16320747137069702,\n",
       " 0.8580328822135925,\n",
       " 2.561342477798462,\n",
       " -1.903623104095459,\n",
       " 0.2718823552131653,\n",
       " -1.178730845451355,\n",
       " 2.1832094192504883,\n",
       " 0.3340303599834442,\n",
       " 1.7061485052108765,\n",
       " 0.601262092590332,\n",
       " 1.4716788530349731,\n",
       " -0.984967827796936,\n",
       " -1.4837545156478882,\n",
       " 0.6444069147109985,\n",
       " -2.0290348529815674,\n",
       " 0.2514573037624359,\n",
       " 0.39376914501190186,\n",
       " -0.6891807913780212,\n",
       " 2.744328498840332,\n",
       " -1.3868869543075562,\n",
       " -0.3101552128791809,\n",
       " -0.42750704288482666,\n",
       " -0.9978958964347839,\n",
       " 1.6591591835021973,\n",
       " -1.9228506088256836,\n",
       " 1.1362625360488892,\n",
       " -0.8550572395324707,\n",
       " 0.9017261266708374,\n",
       " 0.7235410213470459,\n",
       " 1.3338052034378052,\n",
       " -1.414958119392395,\n",
       " 1.654644250869751,\n",
       " -1.25820791721344,\n",
       " -1.974287986755371,\n",
       " -1.5210899114608765,\n",
       " 0.32144948840141296,\n",
       " 4.672589302062988,\n",
       " -1.1029735803604126,\n",
       " 1.0121700763702393,\n",
       " -0.6831909418106079,\n",
       " 2.2424204349517822,\n",
       " -0.12542639672756195,\n",
       " -0.9468351602554321,\n",
       " -1.116971731185913,\n",
       " -1.1794078350067139,\n",
       " -0.46472862362861633,\n",
       " 0.7904332280158997,\n",
       " -2.07559871673584,\n",
       " 3.2876980304718018,\n",
       " -0.18026047945022583,\n",
       " 1.593682050704956,\n",
       " -3.1538188457489014,\n",
       " 0.20685875415802002,\n",
       " 1.38724946975708,\n",
       " -0.00386615889146924,\n",
       " 3.2284839153289795,\n",
       " 0.43016791343688965,\n",
       " 2.9654452800750732,\n",
       " 0.6093611717224121,\n",
       " 0.5438350439071655,\n",
       " -2.0009846687316895,\n",
       " -0.9701786637306213,\n",
       " -0.001673737890087068,\n",
       " 1.3443338871002197,\n",
       " 0.30180004239082336,\n",
       " 2.414994716644287,\n",
       " 0.2627542316913605,\n",
       " -1.526630163192749,\n",
       " 0.9086385369300842,\n",
       " -0.8481812477111816,\n",
       " -1.24575936794281,\n",
       " 0.461110383272171,\n",
       " 0.5987411737442017,\n",
       " 1.0769401788711548,\n",
       " 1.781877040863037,\n",
       " -2.1918365955352783,\n",
       " -0.4407570958137512,\n",
       " 1.3675057888031006,\n",
       " -0.3696044981479645,\n",
       " 1.6923832893371582,\n",
       " -1.796513557434082,\n",
       " 0.909442663192749,\n",
       " 2.6289620399475098,\n",
       " 1.335963249206543,\n",
       " -0.9772853255271912,\n",
       " -1.8448621034622192,\n",
       " -1.0365231037139893,\n",
       " -1.0269309282302856,\n",
       " -0.4820992350578308,\n",
       " 0.8337287306785583,\n",
       " -0.12214341759681702,\n",
       " -1.2408499717712402,\n",
       " -0.4040428102016449,\n",
       " 1.0159244537353516,\n",
       " -1.9085588455200195,\n",
       " -0.19569499790668488,\n",
       " -1.061110019683838,\n",
       " -0.6433729529380798,\n",
       " 1.9110676050186157,\n",
       " -0.9640283584594727,\n",
       " -1.7140817642211914,\n",
       " 2.27771258354187,\n",
       " 0.5517790913581848,\n",
       " 0.34878304600715637,\n",
       " 0.7006872892379761,\n",
       " 1.3336498737335205,\n",
       " 1.579488754272461,\n",
       " 1.1987613439559937,\n",
       " 0.8395794630050659,\n",
       " -0.5152004361152649,\n",
       " -1.7971906661987305,\n",
       " 0.06958133727312088,\n",
       " -2.1619975566864014,\n",
       " 3.8469080924987793,\n",
       " 1.1587259769439697,\n",
       " -2.174107789993286,\n",
       " 0.19674883782863617,\n",
       " -0.34175848960876465,\n",
       " -1.1127716302871704,\n",
       " 0.2606187164783478,\n",
       " -0.7123731374740601,\n",
       " -1.2565549612045288,\n",
       " 0.8993067145347595,\n",
       " -0.6502391695976257,\n",
       " 0.7454220652580261,\n",
       " 7.210686683654785,\n",
       " -17.94413948059082,\n",
       " -0.8587691187858582,\n",
       " 1.4212793111801147,\n",
       " -1.4334217309951782,\n",
       " -1.0761082172393799,\n",
       " -0.6912102103233337,\n",
       " 1.106477975845337,\n",
       " -4.617745876312256,\n",
       " -0.12574586272239685,\n",
       " -1.4389594793319702,\n",
       " 1.1328948736190796,\n",
       " -0.24433289468288422,\n",
       " -0.4810388684272766,\n",
       " 1.4334627389907837,\n",
       " -1.3243637084960938,\n",
       " 1.1885868310928345,\n",
       " 2.1137635707855225,\n",
       " -0.6711245179176331,\n",
       " 2.063598394393921,\n",
       " 1.2336516380310059,\n",
       " 1.4034932851791382,\n",
       " 1.1245824098587036,\n",
       " -0.9662911891937256,\n",
       " 0.9204400777816772,\n",
       " 0.19721823930740356,\n",
       " -0.7061123847961426,\n",
       " -0.5175546407699585,\n",
       " 0.34931012988090515,\n",
       " 0.2613469064235687,\n",
       " 1.1700423955917358,\n",
       " 0.2807304859161377,\n",
       " -0.5991258025169373,\n",
       " -0.15450403094291687,\n",
       " -2.731464147567749,\n",
       " -1.6194698810577393,\n",
       " -0.22494667768478394,\n",
       " 1.138505458831787,\n",
       " 2.1087377071380615,\n",
       " -0.550952136516571,\n",
       " 0.44801896810531616,\n",
       " 1.7072926759719849,\n",
       " 0.2590520977973938,\n",
       " 0.13380230963230133,\n",
       " -4.0475287437438965,\n",
       " 0.47284841537475586,\n",
       " -1.2027853727340698,\n",
       " 0.7896329164505005,\n",
       " 2.4487597942352295,\n",
       " -0.593177080154419,\n",
       " -0.832554817199707,\n",
       " 1.1562985181808472,\n",
       " 1.418383002281189,\n",
       " -0.07921283692121506,\n",
       " -2.770214796066284,\n",
       " -1.7897670269012451,\n",
       " -0.24042092263698578,\n",
       " 0.8920854330062866,\n",
       " -0.45245611667633057,\n",
       " -0.5727834701538086,\n",
       " -0.26642486453056335,\n",
       " 3.1053693294525146,\n",
       " -0.40333282947540283,\n",
       " 2.1035969257354736,\n",
       " 1.102534294128418,\n",
       " -0.8964020609855652,\n",
       " -1.882794976234436,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tender"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
